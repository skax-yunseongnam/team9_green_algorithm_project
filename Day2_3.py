#!/usr/bin/env python
# coding: utf-8

# In[1]:


#pip install streamlit


# In[2]:


#pip install streamlit-ace


# In[1]:


#pip install openai


# In[2]:


import streamlit as st
from streamlit_ace import st_ace
import time
import tracemalloc
import os
import difflib

# =========================
# OpenAI í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„
# =========================
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None
    st.warning("openai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•˜ë‹¤. í„°ë¯¸ë„ì—ì„œ `pip install openai` í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ë¼.")

def get_client():
    if OpenAI is None:
        return None
    api_key = None
    if "OPENAI_API_KEY" in st.secrets:
        api_key = st.secrets["OPENAI_API_KEY"]
    elif os.getenv("OPENAI_API_KEY"):
        api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return None
    return OpenAI(api_key=api_key)

# =========================
# ì‹¤í–‰ + ë©”ëª¨ë¦¬ ì¸¡ì •
# =========================
def run_code(code: str):
    tracemalloc.start()
    start_time = time.time()
    try:
        exec_globals = {}
        exec(code, exec_globals)  # âš ï¸ ì„ì˜ ì½”ë“œ ì‹¤í–‰. ì‹ ë¢°ëœ ì½”ë“œë§Œ ì‚¬ìš©í•˜ë¼.
        output = "ì½”ë“œ ì‹¤í–‰ ì™„ë£Œ"
    except Exception as e:
        output = f"ì˜¤ë¥˜ ë°œìƒ: {e}"
    runtime = time.time() - start_time
    current, peak = tracemalloc.get_traced_memory()
    tracemalloc.stop()
    return output, runtime, peak / 1024.0  # KB

# =========================
# í”„ë¡¬í”„íŠ¸ (ì½”ë“œ-only)
# =========================
SYSTEM_PROMPT_CODE_ONLY = (
    "You are an expert Python performance engineer and green software specialist. "
    "Transform the user's Python code into a functionally equivalent version that minimizes runtime and memory. "
    "Prioritize algorithmic improvements (lower complexity, early exit, pruning, caching/memoization, vectorization, efficient data structures) "
    "then micro-optimizations (in-place ops, fewer allocations, streaming I/O, batching). "
    "Return ONLY the final Python code. No comments, no explanations, no markdown fences."
)

def build_user_prompt(original_code: str, runtime_sec: float | None, memory_kb: float | None):
    rt = f"{runtime_sec:.6f}" if runtime_sec is not None else "unknown"
    mem = f"{memory_kb:.2f}" if memory_kb is not None else "unknown"
    return f"""
[GOAL]
- Reduce runtime and memory usage while preserving functionality and I/O behaviors.
- Keep the code self-contained and runnable as-is (no external files).
- Use only Python stdlib unless strictly necessary.

[CURRENT_METRICS]
- runtime_seconds: {rt}
- peak_memory_kb: {mem}

[CONSTRAINTS]
- Maintain same inputs/outputs and side effects unless provably redundant.
- Avoid unnecessary dependencies.
- Prefer clear, maintainable code over opaque tricks.

[FORMAT]
- Output optimized Python code only.
- No backticks. No explanations. No comments.

[ORIGINAL_CODE]
{original_code}
""".strip()

def request_green_optimized_code(client: "OpenAI", model: str, original_code: str,
                                 runtime_sec: float | None, memory_kb: float | None) -> str:
    prompt = build_user_prompt(original_code, runtime_sec, memory_kb)
    resp = client.chat.completions.create(
        model=model,
        temperature=0.1,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT_CODE_ONLY},
            {"role": "user", "content": prompt},
        ],
    )
    text = (resp.choices[0].message.content or "").strip()
    if text.startswith("```"):
        text = text.strip("`")
        if "\n" in text:
            head, rest = text.split("\n", 1)
            if head.strip().lower() in ("python",):
                text = rest
    return text.strip()

# =========================
# ë³€ê²½ ì´ìœ  ìš”ì•½ (í…ìŠ¤íŠ¸)
# =========================
SYSTEM_PROMPT_EXPLAIN = (
    "You are a concise performance reviewer. Given ORIGINAL and OPTIMIZED Python code and metrics, "
    "summarize WHAT changed and WHY it improves runtime/memory. Be specific but brief in Korean."
)

def request_change_explanation(client: "OpenAI", model: str,
                               original_code: str, optimized_code: str,
                               base_rt: float | None, base_mem: float | None,
                               new_rt: float | None, new_mem: float | None) -> str:
    def fmt(x):
        if x is None:
            return "unknown"
        if isinstance(x, float):
            return f"{x:.6f}"
        return str(x)
    user_prompt = f"""
[ì»¨í…ìŠ¤íŠ¸]
- Original runtime(s): {fmt(base_rt)}, Original peak memory(KB): {fmt(base_mem)}
- Optimized runtime(s): {fmt(new_rt)}, Optimized peak memory(KB): {fmt(new_mem)}

[ìš”ì²­]
- êµ¬ì²´ì ì¸ ë³€ê²½ì  ë¶ˆë¦¿ ëª©ë¡ 5~10ê°œ ë‚´ì™¸ (ì˜ˆ: ì¬ê·€ â†’ ë°˜ë³µ, ë©”ëª¨ì´ì œì´ì…˜ ì¶”ê°€, ë‚´ì¥í•¨ìˆ˜ë¡œ ë²¡í„°í™”, ë¶ˆí•„ìš” ë³µì‚¬ ì œê±° ë“±)
- ê° í•­ëª©ì— ì„±ëŠ¥/ë©”ëª¨ë¦¬ ê°œì„  ì´ìœ ë¥¼ í•œ ì¤„ë¡œ ì„¤ëª…
- í•œêµ­ì–´. ì½”ë“œë¸”ë¡/ë°±í‹± ê¸ˆì§€. ê°„ê²°í•˜ê²Œ.

[ORIGINAL]
{original_code}

[OPTIMIZED]
{optimized_code}
""".strip()
    resp = client.chat.completions.create(
        model=model,
        temperature=0.2,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT_EXPLAIN},
            {"role": "user", "content": user_prompt},
        ],
    )
    return (resp.choices[0].message.content or "").strip()

# =========================
# Diff ìƒì„±
# =========================
def make_unified_diff(original_code: str, optimized_code: str) -> str:
    diff_lines = difflib.unified_diff(
        original_code.splitlines(),
        optimized_code.splitlines(),
        fromfile="original.py",
        tofile="optimized.py",
        lineterm=""
    )
    return "\n".join(diff_lines)

# =========================
# ë°œìêµ­ ê³„ì‚° (ì—ë„ˆì§€/íƒ„ì†Œ)
# =========================
def compute_footprint(runtime_sec: float, peak_kb: float):
    # ìƒìˆ˜ (í•„ìš” ì‹œ ì‚¬ì´ë“œë°”ì— ë…¸ì¶œ ê°€ëŠ¥)
    PUE = 1.67
    PSF = 1
    n_CPUcores = 8
    CPUpower = 15.6        # W per core
    usageCPU_used = 1
    memoryPower = 0.3725   # W/GB
    carbonIntensity = 415.6  # gCO2/kWh

    mem_gb = peak_kb / (1024.0 * 1024.0)  # KB â†’ GB

    power_core = PUE * n_CPUcores * CPUpower * usageCPU_used  # W
    power_mem  = PUE * (mem_gb * memoryPower)                 # W
    power_tot  = power_core + power_mem                       # W

    energy_core = runtime_sec * power_core * PSF / 1000.0     # kWh
    energy_mem  = runtime_sec * power_mem  * PSF / 1000.0     # kWh
    energy_tot  = runtime_sec * power_tot  * PSF / 1000.0     # kWh

    ce_core = energy_core * carbonIntensity                   # gCO2
    ce_mem  = energy_mem  * carbonIntensity                   # gCO2
    ce_tot  = energy_tot  * carbonIntensity                   # gCO2

    r = lambda x, n=4: round(x, n)
    energy_tot = r(energy_tot); ce_tot = r(ce_tot)
    ce_core = r(ce_core); ce_mem = r(ce_mem)

    if (ce_core + ce_mem) > 0:
        ce_core_per = round(ce_core / (ce_core + ce_mem) * 100.0, 2)
        ce_mem_per  = round(ce_mem  / (ce_core + ce_mem) * 100.0, 2)
    else:
        ce_core_per = ce_mem_per = 0.0

    # ë“±ê°€ ì§€í‘œ (ìš”ì²­í•œ ê³µì‹ ê·¸ëŒ€ë¡œ)
    tree_days   = r(ce_tot * 30 / 11000 * 12)     # days
    train_km    = r(ce_tot / 41)
    lightbulb_h = r(energy_tot * 1000 / 60)       # 60W ì „êµ¬ ì‹œê°„
    car_km      = r(ce_tot / 251)

    return {
        "energy_kwh": energy_tot,
        "carbon_g": ce_tot,
        "ce_core_g": ce_core,
        "ce_mem_g": ce_mem,
        "ce_core_per": ce_core_per,
        "ce_mem_per": ce_mem_per,
        "tree_days": tree_days,
        "train_km": train_km,
        "lightbulb_h": lightbulb_h,
        "car_km": car_km,
    }

# =========================
# ì ˆê°ì¹˜ ê³„ì‚°/í‘œì‹œ
# =========================
def _pct_reduction(old: float | None, new: float | None) -> float:
    if old is None or new is None:
        return 0.0
    if old <= 0:
        return 0.0
    return (old - new) / old * 100.0

def _pos(x: float | None) -> float:
    if x is None:
        return 0.0
    return x if x > 0 else 0.0

def compute_savings(base_rt, base_mem_kb, base_fp: dict, opt_rt, opt_mem_kb, opt_fp: dict):
    saved = {
        "runtime_s": (base_rt - opt_rt) if (base_rt is not None and opt_rt is not None) else None,
        "memory_kb": (base_mem_kb - opt_mem_kb) if (base_mem_kb is not None and opt_mem_kb is not None) else None,
        "energy_kwh": base_fp["energy_kwh"] - opt_fp["energy_kwh"],
        "carbon_g":   base_fp["carbon_g"]   - opt_fp["carbon_g"],
        "tree_days":  base_fp["tree_days"]  - opt_fp["tree_days"],
        "train_km":   base_fp["train_km"]   - opt_fp["train_km"],
        "lightbulb_h":base_fp["lightbulb_h"]- opt_fp["lightbulb_h"],
        "car_km":     base_fp["car_km"]     - opt_fp["car_km"],
    }
    pct = {
        "runtime": _pct_reduction(base_rt, opt_rt),
        "memory":  _pct_reduction(base_mem_kb, opt_mem_kb),
        "energy":  _pct_reduction(base_fp["energy_kwh"], opt_fp["energy_kwh"]),
        "carbon":  _pct_reduction(base_fp["carbon_g"],   opt_fp["carbon_g"]),
    }
    return saved, pct

def show_savings_right_only(base_rt, base_mem, base_fp: dict | None,
                            opt_rt, opt_mem, opt_fp: dict):
    if not base_fp:
        st.info("ì›ë³¸ ì¸¡ì •ê°’ì´ ì—†ì–´ ì ˆê°ì¹˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ë‹¤. ë¨¼ì € ìƒë‹¨ì˜ â€˜ì½”ë“œ ì‹¤í–‰â€™ìœ¼ë¡œ ì›ë³¸ì„ ì¸¡ì •í•˜ë¼.")
        return

    saved, pct = compute_savings(base_rt, base_mem, base_fp, opt_rt, opt_mem, opt_fp)

    left, right = st.columns([2, 1])
    with left:
        st.write("### ğŸŒ¿ ì ˆê° ìš”ì•½ (ì›ë³¸ ëŒ€ë¹„)")
        c1, c2 = st.columns(2)
        with c1:
            st.metric("â±ï¸ ì‹¤í–‰ ì‹œê°„ ì ˆê°", f"{_pos(saved['runtime_s']):.4f} s", f"{pct['runtime']:+.1f}%")
            st.metric("ğŸ§  í”¼í¬ ë©”ëª¨ë¦¬ ì ˆê°", f"{_pos(saved['memory_kb']):.2f} KB", f"{pct['memory']:+.1f}%")
        with c2:
            st.metric("âš¡ ì—ë„ˆì§€ ì ˆê°", f"{_pos(saved['energy_kwh']):.4f} kWh", f"{pct['energy']:+.1f}%")
            st.metric("ğŸŒ íƒ„ì†Œë°°ì¶œ ì ˆê°", f"{_pos(saved['carbon_g']):.2f} gCOâ‚‚", f"{pct['carbon']:+.1f}%")

        # ì¦ê°€ ì‹œ ê²½ê³ 
        bad = []
        if saved["energy_kwh"] < 0: bad.append("ì—ë„ˆì§€")
        if saved["carbon_g"]   < 0: bad.append("íƒ„ì†Œ")
        if saved["runtime_s"]  is not None and saved["runtime_s"] < 0: bad.append("ì‹¤í–‰ ì‹œê°„")
        if saved["memory_kb"]  is not None and saved["memory_kb"] < 0: bad.append("ë©”ëª¨ë¦¬")
        if bad:
            st.warning("ë‹¤ìŒ í•­ëª©ì€ ì˜¤íˆë ¤ ì¦ê°€í–ˆë‹¤: " + ", ".join(bad))

        st.write("#### ğŸš‰ ë“±ê°€ ì§€í‘œ ì ˆê°")
        d1, d2, d3, d4 = st.columns(4)
        d1.metric("ğŸŒ³ ë‚˜ë¬´", f"{_pos(saved['tree_days']):.2f} days")
        d2.metric("ğŸš† ê¸°ì°¨", f"{_pos(saved['train_km']):.2f} km")
        d3.metric("ğŸ’¡ ì „êµ¬(60W)", f"{_pos(saved['lightbulb_h']):.2f} h")
        d4.metric("ğŸš— ìë™ì°¨", f"{_pos(saved['car_km']):.2f} km")

        with st.expander("ì„¸ë¶€ ìˆ˜ì¹˜ (ì›ë³¸ â†’ ìµœì í™”)"):
            st.write(
                f"- ì‹¤í–‰ ì‹œê°„: {base_rt:.4f}s â†’ {opt_rt:.4f}s "
                f"({_pos(saved['runtime_s']):.4f}s ì ˆê°, {pct['runtime']:+.1f}%)"
            )
            st.write(
                f"- í”¼í¬ ë©”ëª¨ë¦¬: {base_mem:.2f}KB â†’ {opt_mem:.2f}KB "
                f"({_pos(saved['memory_kb']):.2f}KB ì ˆê°, {pct['memory']:+.1f}%)"
            )
            st.write(
                f"- ì—ë„ˆì§€: {base_fp['energy_kwh']:.4f}kWh â†’ {opt_fp['energy_kwh']:.4f}kWh "
                f"({_pos(saved['energy_kwh']):.4f}kWh ì ˆê°, {pct['energy']:+.1f}%)"
            )
            st.write(
                f"- íƒ„ì†Œ: {base_fp['carbon_g']:.2f}g â†’ {opt_fp['carbon_g']:.2f}g "
                f"({_pos(saved['carbon_g']):.2f}g ì ˆê°, {pct['carbon']:+.1f}%)"
            )

    with right:
        st.write("### ğŸ–¼ï¸ ì¸í¬ ì¹´ë“œ")
        st.image("https://img.icons8.com/fluency/96/000000/deciduous-tree.png", caption="ë‚˜ë¬´ í¡ìˆ˜(ì ˆê°)")
        st.image("https://img.icons8.com/fluency/96/000000/train.png", caption="ê¸°ì°¨ ì£¼í–‰(ì ˆê°)")
        st.image("https://img.icons8.com/fluency/96/000000/light-on.png", caption="60W ì „êµ¬(ì ˆê°)")
        st.image("https://img.icons8.com/fluency/96/000000/car.png", caption="ìë™ì°¨ ì£¼í–‰(ì ˆê°)")
        st.caption("ì•„ì´ì½˜ì€ ì˜ˆì‹œì´ë‹¤. ë¡œì»¬/ì‚¬ë‚´ ê°€ì´ë“œ ì•„ì´ì½˜ìœ¼ë¡œ êµì²´ ê°€ëŠ¥í•˜ë‹¤.")

# =========================
# UI
# =========================
st.set_page_config(page_title="ê·¸ë¦° ì•Œê³ ë¦¬ì¦˜ ì½”ë“œ ì‹¤í–‰ê¸°", layout="wide")
st.title("Python ì½”ë“œ ì‹¤í–‰ê¸° + ê·¸ë¦° ìµœì í™”")

# ì—ë””í„°
code = st_ace(
    language="python",
    theme="monokai",
    keybinding="vscode",
    font_size=14,
    height=300,
    auto_update=True,
)

# ì›ë³¸ ì½”ë“œ ì‹¤í–‰
col_run, col_model = st.columns([1, 2])
with col_run:
    if st.button("ì½”ë“œ ì‹¤í–‰"):
        output, runtime, memory = run_code(code or "")
        st.write("### ì‹¤í–‰ ê²°ê³¼")
        st.write(output)
        st.write(f"### ì‹¤í–‰ ì‹œê°„: {runtime:.4f} ì´ˆ")
        st.write(f"### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory:.2f} KB")
        st.session_state["last_runtime"] = runtime
        st.session_state["last_memory"] = memory

with col_model:
    default_model = "gpt-4.1-mini"
    model_name = st.text_input("ìµœì í™” ëª¨ë¸ëª…", value=default_model, help="OpenAI ëª¨ë¸ëª…ì„ ì…ë ¥í•˜ë¼ (ì˜ˆ: gpt-4.1, gpt-4.1-mini ë“±)")

st.divider()

# ìµœì í™” â†’ ìë™ ì‹¤í–‰ â†’ Diff/ì´ìœ /ì ˆê°
if st.button("ìµœì í™” ì½”ë“œ ìƒì„± ë° ìë™ ì‹¤í–‰ (ì½”ë“œë§Œ ë°˜í™˜)"):
    if not code or not code.strip():
        st.warning("ë¨¼ì € ìƒë‹¨ í¸ì§‘ê¸°ì— ì½”ë“œë¥¼ ì…ë ¥í•˜ë¼.")
    else:
        client = get_client()
        if client is None:
            st.error("OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ì§€ ëª»í–ˆë‹¤. API í‚¤ë¥¼ secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ë¼.")
        else:
            base_rt = st.session_state.get("last_runtime")
            base_mem = st.session_state.get("last_memory")

            with st.spinner("ê·¸ë¦° ìµœì í™” ì½”ë“œë¥¼ ìƒì„± ì¤‘â€¦"):
                try:
                    optimized = request_green_optimized_code(
                        client=client,
                        model=(model_name.strip() or default_model),
                        original_code=code,
                        runtime_sec=base_rt,
                        memory_kb=base_mem,
                    )
                except Exception as e:
                    optimized = ""
                    st.error(f"ìµœì í™” ìš”ì²­ ì¤‘ ì˜¤ë¥˜: {e}")

            if optimized:
                st.write("#### ì¶”ì²œ ì½”ë“œ (GPTê°€ ë°˜í™˜í•œ ì½”ë“œë§Œ)")
                st.code(optimized, language="python")

                # ìë™ ì‹¤í–‰
                out2, rt2, mem2 = run_code(optimized)
                st.write("#### ì¶”ì²œ ì½”ë“œ ì‹¤í–‰ ê²°ê³¼")
                st.write(out2)
                st.write(f"ì‹¤í–‰ ì‹œê°„: {rt2:.4f} ì´ˆ")
                st.write(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem2:.2f} KB")

                # Diff
                st.write("#### ë³€ê²½ëœ ì½”ë“œ Diff")
                diff_text = make_unified_diff(code or "", optimized)
                if diff_text.strip():
                    st.code(diff_text, language="diff")
                else:
                    st.write("ì½”ë“œ ë³€ê²½ì ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ë‹¤.")

                # ë³€ê²½ ì´ìœ  ìš”ì•½
                try:
                    explanation = request_change_explanation(
                        client=client,
                        model=(model_name.strip() or default_model),
                        original_code=code or "",
                        optimized_code=optimized,
                        base_rt=base_rt, base_mem=base_mem,
                        new_rt=rt2, new_mem=mem2
                    )
                    st.write("#### ë³€ê²½ ìš”ì•½ ë° ì´ìœ ")
                    st.markdown(explanation)
                except Exception as e:
                    st.warning(f"ë³€ê²½ ì´ìœ  ìš”ì•½ ìƒì„± ì¤‘ ë¬¸ì œ: {e}")

                # ë°œìêµ­ + ì ˆê°
                if base_rt is not None and base_mem is not None:
                    base_fp = compute_footprint(base_rt, base_mem)
                    opt_fp  = compute_footprint(rt2, mem2)
                    show_savings_right_only(base_rt, base_mem, base_fp, rt2, mem2, opt_fp)
                else:
                    st.info("ì ˆê°ì¹˜ í‘œì‹œë¥¼ ìœ„í•´ ë¨¼ì € â€˜ì½”ë“œ ì‹¤í–‰â€™ìœ¼ë¡œ ì›ë³¸ì„ ì¸¡ì •í•˜ë¼.")

                # ë‹¤ìš´ë¡œë“œ
                st.download_button(
                    label="ìµœì í™” ì½”ë“œ ë‹¤ìš´ë¡œë“œ",
                    data=optimized.encode("utf-8"),
                    file_name="optimized.py",
                    mime="text/x-python",
                )

# ========== ì˜ˆì‹œ ë¹„íš¨ìœ¨ ì½”ë“œ(ì›í•˜ë©´ ë¶™ì—¬ì„œ í…ŒìŠ¤íŠ¸) ==========
with st.expander("ì˜ˆì‹œ: ë¹„íš¨ìœ¨ í”¼ë³´ë‚˜ì¹˜ ì½”ë“œ ì‚½ì…"):
    st.code(
        'def fib(n):\n'
        '    if n <= 1:\n'
        '        return n\n'
        '    return fib(n-1) + fib(n-2)\n\n'
        'n = 35\n'
        'print(f"{n}ë²ˆì§¸ í”¼ë³´ë‚˜ì¹˜ ìˆ˜:", fib(n))\n',
        language="python"
    )


# In[ ]:




